{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2021 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2e0464050974"
   },
   "source": [
    "## Overview\n",
    "\n",
    "This notebook demonstrates how to track metrics and parameters for Vertex AI custom training jobs, and how to perform detailed analysis using this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b95ab729fccd"
   },
   "source": [
    "### Objective\n",
    "\n",
    "In this notebook, you learn how to use Vertex AI SDK for Python to:\n",
    "\n",
    "This tutorial uses the following Google Cloud ML services and resources:\n",
    "- Vertex AI Dataset\n",
    "- Vertex AI Model\n",
    "- Vertex AI Endpoint\n",
    "- Vertex AI Custom Training Job\n",
    "\n",
    "The steps performed include:\n",
    "- Track training parameters and prediction metrics for a custom training job.\n",
    "- Extract and perform analysis for all parameters and metrics within an Experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9fd87cf689bf"
   },
   "source": [
    "### Dataset\n",
    "\n",
    "This example uses the Abalone Dataset. For more information about this dataset please visit: https://archive.ics.uci.edu/ml/datasets/abalone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "### Costs \n",
    "\n",
    "\n",
    "This tutorial uses billable components of Google Cloud:\n",
    "\n",
    "* Vertex AI\n",
    "* Cloud Storage\n",
    "\n",
    "Learn about [Vertex AI\n",
    "pricing](https://cloud.google.com/vertex-ai/pricing) and [Cloud Storage\n",
    "pricing](https://cloud.google.com/storage/pricing), and use the [Pricing\n",
    "Calculator](https://cloud.google.com/products/calculator/)\n",
    "to generate a cost estimate based on your projected usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWEdiXsJg0XY"
   },
   "source": [
    "## Before you begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8bc8a29f9001"
   },
   "source": [
    "#### Set your project ID\n",
    "\n",
    "**If you don't know your project ID**, try the following:\n",
    "* Run `gcloud config list`.\n",
    "* Run `gcloud projects list`.\n",
    "* See the support page: [Locate the project ID](https://support.google.com/googleapi/answer/7014113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cde8e0876d62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = \"manipalpr-1669047537901\"  # @param {type:\"string\"}\n",
    "\n",
    "# Set the project id\n",
    "! gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47bc07d4231b"
   },
   "source": [
    "#### Region\n",
    "\n",
    "You can also change the `REGION` variable used by Vertex AI. Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "959545da671a"
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgPO1eR3CYjk"
   },
   "source": [
    "### Create a Cloud Storage bucket\n",
    "\n",
    "Create a storage bucket to store intermediate artifacts such as datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "MzGDU7TWdts_"
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = \"gs://fractal-parameters-nov27\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EcIXiGsCePi"
   },
   "source": [
    "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "NIq7R4HZCfIc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://fractal-parameters-nov27/...\n"
     ]
    }
   ],
   "source": [
    "! gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XoEqT2Y4DJmf"
   },
   "source": [
    "### Import libraries and define constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9Uo3tifg1kx"
   },
   "source": [
    "Import required libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "pRUOFELefqf1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from google.cloud import aiplatform\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from tensorflow.python.keras.utils import data_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8XJZB3gR8eL"
   },
   "source": [
    "## Initialize Vertex AI and set an _experiment_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xtXZWmYqJ1bh"
   },
   "source": [
    "Define experiment name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "JIOrI-hoJ46P"
   },
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = \"fractal-experiment\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKIsYVjj56_X"
   },
   "source": [
    "Initialize the *client* for Vertex AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Wrlk2B2nJ7-X"
   },
   "outputs": [],
   "source": [
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    staging_bucket=BUCKET_URI,\n",
    "    experiment=EXPERIMENT_NAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6PlilQPFeS_h"
   },
   "source": [
    "## Tracking parameters and metrics in Vertex AI custom training jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8fd397cc4f6"
   },
   "source": [
    "### Download the Dataset to Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "V_T10yTTqcS_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-11-27 04:04:48--  https://storage.googleapis.com/download.tensorflow.org/data/abalone_train.csv\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.152.128, 142.250.128.128, 142.251.6.128, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.152.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 145915 (142K) [text/csv]\n",
      "Saving to: ‘abalone_train.csv.1’\n",
      "\n",
      "abalone_train.csv.1 100%[===================>] 142.50K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2022-11-27 04:04:48 (98.8 MB/s) - ‘abalone_train.csv.1’ saved [145915/145915]\n",
      "\n",
      "Copying file://abalone_train.csv [Content-Type=text/csv]...\n",
      "/ [1 files][142.5 KiB/142.5 KiB]                                                \n",
      "Operation completed over 1 objects/142.5 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!wget https://storage.googleapis.com/download.tensorflow.org/data/abalone_train.csv\n",
    "!gsutil cp abalone_train.csv {BUCKET_URI}/data/\n",
    "\n",
    "gcs_csv_path = f\"{BUCKET_URI}/data/abalone_train.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35QVNhACqcTJ"
   },
   "source": [
    "### Create a Vertex AI Tabular dataset from CSV data\n",
    "\n",
    "A Vertex AI dataset can be used to create an AutoML model or a custom model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "4OfCqaYRqcTJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating TabularDataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.datasets.dataset:Creating TabularDataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create TabularDataset backing LRO: projects/1078378940735/locations/us-central1/datasets/2293469105354702848/operations/997128747129765888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.datasets.dataset:Create TabularDataset backing LRO: projects/1078378940735/locations/us-central1/datasets/2293469105354702848/operations/997128747129765888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabularDataset created. Resource name: projects/1078378940735/locations/us-central1/datasets/2293469105354702848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.datasets.dataset:TabularDataset created. Resource name: projects/1078378940735/locations/us-central1/datasets/2293469105354702848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use this TabularDataset in another session:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.datasets.dataset:To use this TabularDataset in another session:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds = aiplatform.TabularDataset('projects/1078378940735/locations/us-central1/datasets/2293469105354702848')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.datasets.dataset:ds = aiplatform.TabularDataset('projects/1078378940735/locations/us-central1/datasets/2293469105354702848')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'projects/1078378940735/locations/us-central1/datasets/2293469105354702848'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = aiplatform.TabularDataset.create(display_name=\"abalone\", gcs_source=[gcs_csv_path])\n",
    "\n",
    "ds.resource_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VcEOYYolqcTN"
   },
   "source": [
    "### Write the training script\n",
    "\n",
    "Next, you create the training script that is used in the sample custom training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "OauJqJmJqcTO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting training_script.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile training_script.py\n",
    "\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--epochs', dest='epochs',\n",
    "                    default=10, type=int,\n",
    "                    help='Number of epochs.')\n",
    "parser.add_argument('--num_units', dest='num_units',\n",
    "                    default=64, type=int,\n",
    "                    help='Number of unit for first layer.')\n",
    "args = parser.parse_args()\n",
    "\n",
    "col_names = [\"Length\", \"Diameter\", \"Height\", \"Whole weight\", \"Shucked weight\", \"Viscera weight\", \"Shell weight\", \"Age\"]\n",
    "target = \"Age\"\n",
    "\n",
    "def aip_data_to_dataframe(wild_card_path):\n",
    "    return pd.concat([pd.read_csv(fp.numpy().decode(), names=col_names)\n",
    "                      for fp in tf.data.Dataset.list_files([wild_card_path])])\n",
    "\n",
    "def get_features_and_labels(df):\n",
    "    return df.drop(target, axis=1).values, df[target].values\n",
    "\n",
    "def data_prep(wild_card_path):\n",
    "    return get_features_and_labels(aip_data_to_dataframe(wild_card_path))\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([layers.Dense(args.num_units), layers.Dense(1)])\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "model.fit(*data_prep(os.environ[\"AIP_TRAINING_DATA_URI\"]),\n",
    "          epochs=args.epochs ,\n",
    "          validation_data=data_prep(os.environ[\"AIP_VALIDATION_DATA_URI\"]))\n",
    "print(model.evaluate(*data_prep(os.environ[\"AIP_TEST_DATA_URI\"])))\n",
    "\n",
    "# save as Vertex AI Managed model\n",
    "tf.saved_model.save(model, os.environ[\"AIP_MODEL_DIR\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yp2clkOJSDhR"
   },
   "source": [
    "### Launch a custom training job and track its training parameters on Vertex ML Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "btb6d48lqcTT"
   },
   "outputs": [],
   "source": [
    "job = aiplatform.CustomTrainingJob(\n",
    "    display_name=\"train-abalone-job-nov27\",\n",
    "    script_path=\"training_script.py\",\n",
    "    container_uri=\"us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-8:latest\",\n",
    "    requirements=[\"gcsfs==0.7.1\"],\n",
    "    model_serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-8:latest\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k_QorXXztzPH"
   },
   "source": [
    "Start a new experiment run to track training parameters and start the training job. Note that this operation will take around 10 mins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "oVTORjQpJ7-Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Associating projects/1078378940735/locations/us-central1/metadataStores/default/contexts/fractal-experiment-custom-training-run-nov27-1 to Experiment: fractal-experiment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.metadata.experiment_resources:Associating projects/1078378940735/locations/us-central1/metadataStores/default/contexts/fractal-experiment-custom-training-run-nov27-1 to Experiment: fractal-experiment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training script copied to:\n",
      "gs://fractal-parameters-nov27/aiplatform-2022-11-27-04:08:58.059-aiplatform_custom_trainer_script-0.1.tar.gz.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.utils.source_utils:Training script copied to:\n",
      "gs://fractal-parameters-nov27/aiplatform-2022-11-27-04:08:58.059-aiplatform_custom_trainer_script-0.1.tar.gz.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Output directory:\n",
      "gs://fractal-parameters-nov27/aiplatform-custom-training-2022-11-27-04:08:58.143 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.training_jobs:Training Output directory:\n",
      "gs://fractal-parameters-nov27/aiplatform-custom-training-2022-11-27-04:08:58.143 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No dataset split provided. The service will use a default split.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.training_jobs:No dataset split provided. The service will use a default split.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View Training:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/4456786545428398080?project=1078378940735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.training_jobs:View Training:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/4456786545428398080?project=1078378940735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomTrainingJob projects/1078378940735/locations/us-central1/trainingPipelines/4456786545428398080 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.training_jobs:CustomTrainingJob projects/1078378940735/locations/us-central1/trainingPipelines/4456786545428398080 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomTrainingJob projects/1078378940735/locations/us-central1/trainingPipelines/4456786545428398080 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.training_jobs:CustomTrainingJob projects/1078378940735/locations/us-central1/trainingPipelines/4456786545428398080 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomTrainingJob projects/1078378940735/locations/us-central1/trainingPipelines/4456786545428398080 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.training_jobs:CustomTrainingJob projects/1078378940735/locations/us-central1/trainingPipelines/4456786545428398080 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomTrainingJob projects/1078378940735/locations/us-central1/trainingPipelines/4456786545428398080 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.training_jobs:CustomTrainingJob projects/1078378940735/locations/us-central1/trainingPipelines/4456786545428398080 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomTrainingJob projects/1078378940735/locations/us-central1/trainingPipelines/4456786545428398080 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.training_jobs:CustomTrainingJob projects/1078378940735/locations/us-central1/trainingPipelines/4456786545428398080 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View backing custom job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/3588576979764379648?project=1078378940735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.training_jobs:View backing custom job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/3588576979764379648?project=1078378940735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomTrainingJob projects/1078378940735/locations/us-central1/trainingPipelines/4456786545428398080 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.training_jobs:CustomTrainingJob projects/1078378940735/locations/us-central1/trainingPipelines/4456786545428398080 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomTrainingJob run completed. Resource name: projects/1078378940735/locations/us-central1/trainingPipelines/4456786545428398080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.training_jobs:CustomTrainingJob run completed. Resource name: projects/1078378940735/locations/us-central1/trainingPipelines/4456786545428398080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model available at projects/1078378940735/locations/us-central1/models/4120232908113838080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.training_jobs:Model available at projects/1078378940735/locations/us-central1/models/4120232908113838080\n"
     ]
    }
   ],
   "source": [
    "aiplatform.start_run(\n",
    "    \"custom-training-run-nov27-1\"\n",
    ")  # Change this to your desired run name\n",
    "parameters = {\"epochs\": 10, \"num_units\": 64}\n",
    "aiplatform.log_params(parameters)\n",
    "\n",
    "model = job.run(\n",
    "    ds,\n",
    "    replica_count=1,\n",
    "    model_display_name=\"abalone-model\",\n",
    "    args=[f\"--epochs={parameters['epochs']}\", f\"--num_units={parameters['num_units']}\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5vhDsMJNqcTW"
   },
   "source": [
    "### Deploy model and calculate prediction metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-uCOL3Naap4"
   },
   "source": [
    "Next, deploy your Vertex AI Model resource to a Vertex AI Endpoint resource. This operation will take 10-20 mins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y9GH72wWqcTX"
   },
   "outputs": [],
   "source": [
    "endpoint = model.deploy(machine_type=\"n1-standard-4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JY-5skFhasWs"
   },
   "source": [
    "### Prediction dataset preparation and online prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "saw50bqwa-dR"
   },
   "source": [
    "Once model is deployed, perform online prediction using the `abalone_test` dataset and calculate prediction metrics.\n",
    "\n",
    "Prepare the prediction dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ABZQmqsWISQv"
   },
   "outputs": [],
   "source": [
    "def read_data(uri):\n",
    "    dataset_path = data_utils.get_file(\"abalone_test.data\", uri)\n",
    "    col_names = [\n",
    "        \"Length\",\n",
    "        \"Diameter\",\n",
    "        \"Height\",\n",
    "        \"Whole weight\",\n",
    "        \"Shucked weight\",\n",
    "        \"Viscera weight\",\n",
    "        \"Shell weight\",\n",
    "        \"Age\",\n",
    "    ]\n",
    "    dataset = pd.read_csv(\n",
    "        dataset_path,\n",
    "        names=col_names,\n",
    "        na_values=\"?\",\n",
    "        comment=\"\\t\",\n",
    "        sep=\",\",\n",
    "        skipinitialspace=True,\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def get_features_and_labels(df):\n",
    "    target = \"Age\"\n",
    "    return df.drop(target, axis=1).values, df[target].values\n",
    "\n",
    "\n",
    "test_dataset, test_labels = get_features_and_labels(\n",
    "    read_data(\n",
    "        \"https://storage.googleapis.com/download.tensorflow.org/data/abalone_test.csv\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_HphZ38obJeB"
   },
   "source": [
    "Perform online prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eXD-OvsrKmCt"
   },
   "outputs": [],
   "source": [
    "prediction = endpoint.predict(test_dataset.tolist())\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TDKiv_O7bNwE"
   },
   "source": [
    "Calculate and track prediction evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cj0fHucbKopn"
   },
   "outputs": [],
   "source": [
    "mse = mean_squared_error(test_labels, prediction.predictions)\n",
    "mae = mean_absolute_error(test_labels, prediction.predictions)\n",
    "\n",
    "aiplatform.log_metrics({\"mse\": mse, \"mae\": mae})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCGmesdIbbHf"
   },
   "source": [
    "### Extract all parameters and metrics created during this experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KlcEBou-Pl4Z"
   },
   "outputs": [],
   "source": [
    "aiplatform.get_experiment_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTHvPMweMlP1"
   },
   "source": [
    "### View data in the Cloud Console"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F19_5lw0MqXv"
   },
   "source": [
    "Parameters and metrics can also be viewed in the Cloud Console. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GmN9vE9pqqzt"
   },
   "outputs": [],
   "source": [
    "print(\"Vertex AI Experiments:\")\n",
    "print(\n",
    "    f\"https://console.cloud.google.com/ai/platform/experiments/experiments?folder=&organizationId=&project={PROJECT_ID}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpV-iwP9qw9c"
   },
   "source": [
    "## Cleaning up\n",
    "\n",
    "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
    "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
    "\n",
    "Otherwise, you can delete the individual resources you created in this tutorial:\n",
    "Training Job\n",
    "Model\n",
    "Cloud Storage Bucket\n",
    "\n",
    "* Vertex AI Dataset\n",
    "* Training Job\n",
    "* Model\n",
    "* Endpoint\n",
    "* Cloud Storage Bucket\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rwPZoZISHhaY"
   },
   "outputs": [],
   "source": [
    "# Warning: Setting this to true will delete everything in your bucket\n",
    "delete_bucket = False\n",
    "\n",
    "# Delete dataset\n",
    "ds.delete()\n",
    "\n",
    "# Delete experiment\n",
    "experiment = aiplatform.Experiment(\n",
    "    experiment_name=EXPERIMENT_NAME, project=PROJECT_ID, location=REGION\n",
    ")\n",
    "experiment.delete()\n",
    "\n",
    "# Delete the training job\n",
    "job.delete()\n",
    "\n",
    "# Undeploy model from endpoint\n",
    "endpoint.undeploy_all()\n",
    "\n",
    "# Delete the endpoint\n",
    "endpoint.delete()\n",
    "\n",
    "# Delete the model\n",
    "model.delete()\n",
    "\n",
    "\n",
    "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "    ! gsutil -m rm -r $BUCKET_URI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "sdk-metric-parameter-tracking-for-custom-jobs.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m100",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
